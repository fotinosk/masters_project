# To-Do List #

Include any details here for future improvements

- Add tensorboard to PPO DONE
- Add evaluator to PPO, to stop over-training       DONE
- Train on both DDPG and PPO
- Create mode of failure for testing
- Experiment with different PPO architecture
- Understand PPO
- Fix user warning in Augment
- Add print colors to the failure and success       DONE
- Maybe add verbosity option(?)
- Make common file, so that trajectory.py etc doesn't have to be copied in
- Make Replay Buffer O(1)